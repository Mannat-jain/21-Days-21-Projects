# ðŸ“š 21 Projects in 21 Days â€“ ML, Deep Learning & GenAI

Welcome to my 21 Days, 21 Projects journey with GeeksforGeeks!

This repo is a daily log of the projects Iâ€™ll be building â€” covering Machine Learning, Deep Learning, and Generative AI.
________________________________________________________________________________________________________________________________
The goal?

ðŸš€ Build consistency

ðŸ§  Strengthen hands-on skills

ðŸŽ¯ Learn by doing
________________________________________________________________________________________________________________________________

ðŸ“… Challenge Overview

Duration: 21 Days

Projects: 21 end-to-end projects

Focus Areas: Machine Learning, Deep Learning, Generative AI

Daily Routine: Live class â†’ implement project â†’ push to GitHub
________________________________________________________________________________________________________________________________

ðŸ› ï¸ Tech Stack

Languages: Python

Core: NumPy, Pandas, Scikit-learn

Deep Learning: TensorFlow / PyTorch

GenAI: Hugging Face, OpenAI, LangChain (where applicable)

Other Tools: Streamlit, Flask, Jupyter
________________________________________________________________________________________________________________________________

ðŸŒŸ Key Learnings (to be updated daily)

ðŸ“Œ Day 1 â€“ Titanic Dataset ðŸ›³ï¸
- Covered: EDA, cleaning, feature engineering, correlation analysis  
- Key Learning: Choosing the right plots for the right analysis makes insights clearer.
  
ðŸ“Œ Day 2 â€“ Netflix Dataset ðŸ¿
- Covered: Data cleaning & transformation, time-series analysis, text data manipulation, geographical & rating analysis, feature engineering, advanced visualization
- Key Learning: EDA isnâ€™t just about numbers â€” the real value comes from turning raw data into stories that highlight trends, shifts, and patterns clearly.

ðŸ“Œ Day 3 â€“ House Price Prediction (Regression) ðŸ 
- Covered: Data import via Kaggle API, preprocessing, feature engineering, categorical encoding, Linear Regression vs. XGBoost, model evaluation.
- Key Learning: Regression demands careful handling of targets & features, while the Kaggle API made workflows cleaner and reproducible.

ðŸ“Œ Day 4 â€“ Sentiment Analysis (NLP) ðŸ’¬
- Covered: Text preprocessing (stopwords, stemming/lemmatization), vectorization (BoW & TF-IDF), ML models for sentiment classification, evaluation (precision/recall/F1).
- Key Learning: In NLP, strong preprocessing + representation often matter more than the choice of model.

ðŸ“Œ Day 5 â€“ Customer Segmentation (Clustering) ðŸ›ï¸
- Covered: 2D/3D EDA, k-means (income & age-based), optimal k via Elbow Method, hierarchical clustering validation, persona creation for marketing.
- Key Learning: Clustering depends heavily on feature choice + validation â€” the right setup makes results business-ready.

ðŸ“Œ Day 6 â€“ Predicting Future Store Sales (Time Series) ðŸªðŸ“ˆ
- Covered: Time series decomposition, stationarity testing (ADF), log transform & differencing, ACF/PACF for parameter selection, ARIMA baseline, SARIMA for trend + seasonality, RMSE evaluation.
- Key Learning: Stationarity is the backbone of forecasting â€” SARIMA proved far superior by modeling seasonal patterns effectively.
________________________________________________________________________________________________________________________________

ðŸ“Œ Notes

This repo isnâ€™t just about code dumps â€” Iâ€™ll also be documenting learnings, challenges, and takeaways for each project.

Discipline > Perfection âœ¨
________________________________________________________________________________________________________________________________

ðŸ”— Connect

Follow my journey here:

ðŸ’¼ LinkedIn: https://www.linkedin.com/in/mannatjain14/

ðŸ“‚ GeeksforGeeks Challenge: https://github.com/Mannat-jain/GFG160 and https://github.com/Mannat-jain/21-Days-21-Projects
